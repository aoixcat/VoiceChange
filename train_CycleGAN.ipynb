{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import librosa\n",
    "import pyworld\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf \n",
    "from preprocess import *\n",
    "\n",
    "from model import CycleGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_A_dir = './data/voice_data/Test' # 300\n",
    "train_B_dir = './data/voice_data/Test' # 100\n",
    "\n",
    "model_dir = './model/f4_m2_mc24_fr256_model_U1'\n",
    "model_name = 'f4_m2_mc24_fr256_model_U1.ckpt'\n",
    "\n",
    "pre_model_dir = './model/f4_m2_mc24_fr256_model_U1'\n",
    "pre_model_name = 'f4_m2_mc24_fr256_model_U1.ckpt'\n",
    "\n",
    "figure_dir = \"./figures/f4_m2_mc24_fr256_model_U1\"\n",
    "\n",
    "random_seed = 0\n",
    "np.random.seed(random_seed)\n",
    "validation_A_dir = None\n",
    "validation_B_dir = None\n",
    "tensorboard_log_dir = './log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "isContinue = False\n",
    "\n",
    "num_epochs = 10000\n",
    "num_pre_epochs = 0\n",
    "mini_batch_size = 1\n",
    "generator_learning_rate = 0.0002\n",
    "generator_learning_rate_decay = generator_learning_rate / 200000\n",
    "discriminator_learning_rate = 0.0001\n",
    "discriminator_learning_rate_decay = discriminator_learning_rate / 200000\n",
    "sampling_rate = 16000\n",
    "num_mcep = 24\n",
    "frame_period = 5.0\n",
    "n_frames = 256\n",
    "lambda_cycle = 10\n",
    "lambda_identity = 5\n",
    "\n",
    "lossG = []\n",
    "lossD = []\n",
    "loss_num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Data...\n",
      "Data Loading...\n",
      "Extracting f0 and mcep...\n",
      "process: 1\n",
      "process: 2\n",
      "Saving f0 Data...\n",
      "process: 3\n",
      "process: 4\n",
      "Saving mcep Data...\n",
      "Preprocessing Done.\n",
      "Time Elapsed for Data Preprocessing: 00:00:05\n",
      "Model Loading...\n",
      "Training start.\n",
      "Epoch: 1\n"
     ]
    }
   ],
   "source": [
    "print('Preprocessing Data...')\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"Data Loading...\")\n",
    "\n",
    "wavs_A = load_wavs(wav_dir = train_A_dir, sr = sampling_rate)\n",
    "wavs_B = load_wavs(wav_dir = train_B_dir, sr = sampling_rate)\n",
    "\n",
    "print(\"Extracting f0 and mcep...\")\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "print(\"process: 1\")\n",
    "f0s_A, timeaxes_A, sps_A, aps_A, coded_sps_A = world_encode_data(wavs = wavs_A, fs = sampling_rate, frame_period = frame_period, coded_dim = num_mcep)\n",
    "f0s_B, timeaxes_B, sps_B, aps_B, coded_sps_B = world_encode_data(wavs = wavs_B, fs = sampling_rate, frame_period = frame_period, coded_dim = num_mcep)\n",
    "\n",
    "del wavs_A, timeaxes_A, sps_A, aps_A\n",
    "del wavs_B, timeaxes_B, sps_B, aps_B\n",
    "\n",
    "print(\"process: 2\")\n",
    "log_f0s_mean_A, log_f0s_std_A = logf0_statistics(f0s_A)\n",
    "log_f0s_mean_B, log_f0s_std_B = logf0_statistics(f0s_B)\n",
    "\n",
    "print(\"Saving f0 Data...\")\n",
    "np.savez(os.path.join(model_dir, 'logf0s_normalization.npz'), mean_A = log_f0s_mean_A, std_A = log_f0s_std_A, mean_B = log_f0s_mean_B, std_B = log_f0s_std_B)\n",
    "\n",
    "del f0s_A, log_f0s_mean_A, log_f0s_std_A\n",
    "del f0s_B, log_f0s_mean_B, log_f0s_std_B\n",
    "\n",
    "print(\"process: 3\")\n",
    "coded_sps_A_transposed = transpose_in_list(lst = coded_sps_A)\n",
    "coded_sps_B_transposed = transpose_in_list(lst = coded_sps_B)\n",
    "\n",
    "del coded_sps_A\n",
    "del coded_sps_B\n",
    "\n",
    "print(\"process: 4\")\n",
    "coded_sps_A_norm, coded_sps_A_mean, coded_sps_A_std = coded_sps_normalization_fit_transoform(coded_sps = coded_sps_A_transposed)\n",
    "coded_sps_B_norm, coded_sps_B_mean, coded_sps_B_std = coded_sps_normalization_fit_transoform(coded_sps = coded_sps_B_transposed)\n",
    "\n",
    "print(\"Saving mcep Data...\")\n",
    "np.savez(os.path.join(model_dir, 'mcep_normalization.npz'), mean_A = coded_sps_A_mean, std_A = coded_sps_A_std, mean_B = coded_sps_B_mean, std_B = coded_sps_B_std)    \n",
    "\n",
    "end_time = time.time()\n",
    "time_elapsed = end_time - start_time\n",
    "\n",
    "print('Preprocessing Done.')\n",
    "\n",
    "print('Time Elapsed for Data Preprocessing: %02d:%02d:%02d' % (time_elapsed // 3600, (time_elapsed % 3600 // 60), (time_elapsed % 60 // 1)))\n",
    "\n",
    "\n",
    "print(\"Model Loading...\")\n",
    "\n",
    "model = CycleGAN(num_features = num_mcep)\n",
    "if (isContinue):\n",
    "    model.load(filepath = os.path.join(pre_model_dir, pre_model_name))\n",
    "\n",
    "print(\"Training start.\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch += num_pre_epochs + 1\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    print('Epoch: %d' % epoch)\n",
    "\n",
    "    dataset_A, dataset_B = sample_train_data(dataset_A = coded_sps_A_norm, dataset_B = coded_sps_B_norm, n_frames = n_frames)\n",
    "\n",
    "    n_samples = dataset_A.shape[0]\n",
    "\n",
    "    for i in range(n_samples // mini_batch_size):\n",
    "\n",
    "        num_iterations = n_samples // mini_batch_size * epoch + i\n",
    "\n",
    "        if num_iterations > 10000:\n",
    "            lambda_identity = 0\n",
    "        if num_iterations > 200000:\n",
    "            generator_learning_rate = max(0, generator_learning_rate - generator_learning_rate_decay)\n",
    "            discriminator_learning_rate = max(0, discriminator_learning_rate - discriminator_learning_rate_decay)\n",
    "\n",
    "        start = i * mini_batch_size\n",
    "        end = (i + 1) * mini_batch_size\n",
    "\n",
    "        generator_loss, discriminator_loss = model.train(input_A = dataset_A[start:end], input_B = dataset_B[start:end], lambda_cycle = lambda_cycle, lambda_identity = lambda_identity, generator_learning_rate = generator_learning_rate, discriminator_learning_rate = discriminator_learning_rate)\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            lossG.append(generator_loss)\n",
    "            lossD.append(discriminator_loss)\n",
    "            loss_num += 1\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        model.save(directory = model_dir, filename = model_name)\n",
    "    if (epoch % 2000 == 0):\n",
    "        model.save(directory = model_dir, filename = model_name + \"_\" + str(epoch))\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        if not os.path.exists(figure_dir):\n",
    "            os.makedirs(figure_dir)\n",
    "        x = np.linspace(0, loss_num, loss_num)\n",
    "        plt.figure()\n",
    "        plt.plot(x, lossG, label=\"Gen\")\n",
    "        plt.plot(x, lossD, label=\"Dis\")\n",
    "        plt.savefig(figure_dir + \"/\" + \"epoch_{:05}\".format(epoch) + \".png\")\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print('Time Elapsed for one epoch: %02d:%02d:%02d' % (elapsed_time // 3600, (elapsed_time % 3600 // 60), (elapsed_time % 60 // 1)))        \n",
    "\n",
    "model.save(directory = model_dir, filename = model_name)\n",
    "\n",
    "x = np.linspace(0, loss_num, loss_num)\n",
    "\n",
    "plt.plot(x, lossG, label=\"Gen\")\n",
    "plt.plot(x, lossD, label=\"Dis\")\n",
    "plt.savefig(figure_dir + \"/\" + \"epoch_{:05}\".format(num_epochs) + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
