{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 変更点\n",
    "+ preprocess loadwave の部分を，100に制限．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import librosa\n",
    "import pyworld\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model import CycleGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_A_dir = './data/vcc2016_training/SF1'\n",
    "# train_B_dir = './data/vcc2016_training/TF2'\n",
    "train_A_dir = './data/voice_data/F3'\n",
    "train_B_dir = './data/voice_data/M2'\n",
    "model_dir = './model/f3_m2_ep8000_mc64'\n",
    "model_name = 'f3_m2_8000_mc64.ckpt'\n",
    "figure_dir = \"./figures/f3_m2_8000_mc64\"\n",
    "random_seed = 0\n",
    "# validation_A_dir = './data/evaluation_all/SF1' # or None\n",
    "# validation_B_dir = './data/evaluation_all/TF2' # or None\n",
    "validation_A_dir = None\n",
    "validation_B_dir = None\n",
    "output_dir = './validation_output'\n",
    "tensorboard_log_dir = './log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wavs(wav_dir, sr):\n",
    "    \n",
    "    debug_num = 0\n",
    "    wavs = list()\n",
    "    for file in os.listdir(wav_dir):\n",
    "        debug_num += 1\n",
    "        if (debug_num > 100):\n",
    "            break\n",
    "        file_path = os.path.join(wav_dir, file)\n",
    "        wav, _ = librosa.load(file_path, sr = sr, mono = True)\n",
    "        #wav = wav.astype(np.float64)\n",
    "        wavs.append(wav)\n",
    "\n",
    "    return wavs\n",
    "\n",
    "def world_decompose(wav, fs, frame_period = 5.0):\n",
    "\n",
    "    # Decompose speech signal into f0, spectral envelope and aperiodicity using WORLD\n",
    "    wav = wav.astype(np.float64)\n",
    "    f0, timeaxis = pyworld.harvest(wav, fs, frame_period = frame_period, f0_floor = 71.0, f0_ceil = 800.0)\n",
    "    sp = pyworld.cheaptrick(wav, f0, timeaxis, fs)\n",
    "    ap = pyworld.d4c(wav, f0, timeaxis, fs)\n",
    "\n",
    "    return f0, timeaxis, sp, ap\n",
    "\n",
    "def world_encode_spectral_envelop(sp, fs, dim = 24):\n",
    "\n",
    "    # Get Mel-cepstral coefficients (MCEPs)\n",
    "\n",
    "    #sp = sp.astype(np.float64)\n",
    "    coded_sp = pyworld.code_spectral_envelope(sp, fs, dim)\n",
    "\n",
    "    return coded_sp\n",
    "\n",
    "def world_decode_spectral_envelop(coded_sp, fs):\n",
    "\n",
    "    fftlen = pyworld.get_cheaptrick_fft_size(fs)\n",
    "    #coded_sp = coded_sp.astype(np.float32)\n",
    "    #coded_sp = np.ascontiguousarray(coded_sp)\n",
    "    decoded_sp = pyworld.decode_spectral_envelope(coded_sp, fs, fftlen)\n",
    "\n",
    "    return decoded_sp\n",
    "\n",
    "\n",
    "def world_encode_data(wavs, fs, frame_period = 5.0, coded_dim = 24):\n",
    "\n",
    "    f0s = list()\n",
    "    timeaxes = list()\n",
    "    sps = list()\n",
    "    aps = list()\n",
    "    coded_sps = list()\n",
    "\n",
    "    for wav in wavs:\n",
    "        f0, timeaxis, sp, ap = world_decompose(wav = wav, fs = fs, frame_period = frame_period)\n",
    "        coded_sp = world_encode_spectral_envelop(sp = sp, fs = fs, dim = coded_dim)\n",
    "        f0s.append(f0)\n",
    "        timeaxes.append(timeaxis)\n",
    "        sps.append(sp)\n",
    "        aps.append(ap)\n",
    "        coded_sps.append(coded_sp)\n",
    "\n",
    "    return f0s, timeaxes, sps, aps, coded_sps\n",
    "\n",
    "\n",
    "def transpose_in_list(lst):\n",
    "\n",
    "    transposed_lst = list()\n",
    "    for array in lst:\n",
    "        transposed_lst.append(array.T)\n",
    "    return transposed_lst\n",
    "\n",
    "\n",
    "def world_decode_data(coded_sps, fs):\n",
    "\n",
    "    decoded_sps =  list()\n",
    "\n",
    "    for coded_sp in coded_sps:\n",
    "        decoded_sp = world_decode_spectral_envelop(coded_sp, fs)\n",
    "        decoded_sps.append(decoded_sp)\n",
    "\n",
    "    return decoded_sps\n",
    "\n",
    "\n",
    "def world_speech_synthesis(f0, decoded_sp, ap, fs, frame_period):\n",
    "\n",
    "    #decoded_sp = decoded_sp.astype(np.float64)\n",
    "    wav = pyworld.synthesize(f0, decoded_sp, ap, fs, frame_period)\n",
    "    # Librosa could not save wav if not doing so\n",
    "    wav = wav.astype(np.float32)\n",
    "\n",
    "    return wav\n",
    "\n",
    "\n",
    "def world_synthesis_data(f0s, decoded_sps, aps, fs, frame_period):\n",
    "\n",
    "    wavs = list()\n",
    "\n",
    "    for f0, decoded_sp, ap in zip(f0s, decoded_sps, aps):\n",
    "        wav = world_speech_synthesis(f0, decoded_sp, ap, fs, frame_period)\n",
    "        wavs.append(wav)\n",
    "\n",
    "    return wavs\n",
    "\n",
    "\n",
    "def coded_sps_normalization_fit_transoform(coded_sps):\n",
    "\n",
    "    coded_sps_concatenated = np.concatenate(coded_sps, axis = 1)\n",
    "    coded_sps_mean = np.mean(coded_sps_concatenated, axis = 1, keepdims = True)\n",
    "    coded_sps_std = np.std(coded_sps_concatenated, axis = 1, keepdims = True)\n",
    "\n",
    "    coded_sps_normalized = list()\n",
    "    for coded_sp in coded_sps:\n",
    "        coded_sps_normalized.append((coded_sp - coded_sps_mean) / coded_sps_std)\n",
    "    \n",
    "    return coded_sps_normalized, coded_sps_mean, coded_sps_std\n",
    "\n",
    "def coded_sps_normalization_transoform(coded_sps, coded_sps_mean, coded_sps_std):\n",
    "\n",
    "    coded_sps_normalized = list()\n",
    "    for coded_sp in coded_sps:\n",
    "        coded_sps_normalized.append((coded_sp - coded_sps_mean) / coded_sps_std)\n",
    "    \n",
    "    return coded_sps_normalized\n",
    "\n",
    "def coded_sps_normalization_inverse_transoform(normalized_coded_sps, coded_sps_mean, coded_sps_std):\n",
    "\n",
    "    coded_sps = list()\n",
    "    for normalized_coded_sp in normalized_coded_sps:\n",
    "        coded_sps.append(normalized_coded_sp * coded_sps_std + coded_sps_mean)\n",
    "\n",
    "    return coded_sps\n",
    "\n",
    "def coded_sp_padding(coded_sp, multiple = 4):\n",
    "\n",
    "    num_features = coded_sp.shape[0]\n",
    "    num_frames = coded_sp.shape[1]\n",
    "    num_frames_padded = int(np.ceil(num_frames / multiple)) * multiple\n",
    "    num_frames_diff = num_frames_padded - num_frames\n",
    "    num_pad_left = num_frames_diff // 2\n",
    "    num_pad_right = num_frames_diff - num_pad_left\n",
    "    coded_sp_padded = np.pad(coded_sp, ((0, 0), (num_pad_left, num_pad_right)), 'constant', constant_values = 0)\n",
    "\n",
    "    return coded_sp_padded\n",
    "\n",
    "def wav_padding(wav, sr, frame_period, multiple = 4):\n",
    "\n",
    "    assert wav.ndim == 1 \n",
    "    num_frames = len(wav)\n",
    "    num_frames_padded = int((np.ceil((np.floor(num_frames / (sr * elf.frame_period / 1000)) + 1) / multiple + 1) * multiple - 1) * (sr * self.frame_period / 1000))\n",
    "    num_frames_diff = num_frames_padded - num_frames\n",
    "    num_pad_left = num_frames_diff // 2\n",
    "    num_pad_right = num_frames_diff - num_pad_left\n",
    "    wav_padded = np.pad(wav, (num_pad_left, num_pad_right), 'constant', constant_values = 0)\n",
    "\n",
    "    return wav_padded\n",
    "\n",
    "\n",
    "def logf0_statistics(f0s):\n",
    "\n",
    "    log_f0s_concatenated = np.ma.log(np.concatenate(f0s))\n",
    "    log_f0s_mean = log_f0s_concatenated.mean()\n",
    "    log_f0s_std = log_f0s_concatenated.std()\n",
    "\n",
    "    return log_f0s_mean, log_f0s_std\n",
    "\n",
    "def pitch_conversion(f0, mean_log_src, std_log_src, mean_log_target, std_log_target):\n",
    "\n",
    "    # Logarithm Gaussian normalization for Pitch Conversions\n",
    "    f0_converted = np.exp((np.log(f0) - mean_log_src) / std_log_src * std_log_target + mean_log_target)\n",
    "\n",
    "    return f0_converted\n",
    "\n",
    "def wavs_to_specs(wavs, n_fft = 1024, hop_length = None):\n",
    "\n",
    "    stfts = list()\n",
    "    for wav in wavs:\n",
    "        stft = librosa.stft(wav, n_fft = n_fft, hop_length = hop_length)\n",
    "        stfts.append(stft)\n",
    "\n",
    "    return stfts\n",
    "\n",
    "\n",
    "def wavs_to_mfccs(wavs, sr, n_fft = 1024, hop_length = None, n_mels = 128, n_mfcc = 24):\n",
    "\n",
    "    mfccs = list()\n",
    "    for wav in wavs:\n",
    "        mfcc = librosa.feature.mfcc(y = wav, sr = sr, n_fft = n_fft, hop_length = hop_length, n_mels = n_mels, n_mfcc = n_mfcc)\n",
    "        mfccs.append(mfcc)\n",
    "\n",
    "    return mfccs\n",
    "\n",
    "\n",
    "def mfccs_normalization(mfccs):\n",
    "\n",
    "    mfccs_concatenated = np.concatenate(mfccs, axis = 1)\n",
    "    mfccs_mean = np.mean(mfccs_concatenated, axis = 1, keepdims = True)\n",
    "    mfccs_std = np.std(mfccs_concatenated, axis = 1, keepdims = True)\n",
    "\n",
    "    mfccs_normalized = list()\n",
    "    for mfcc in mfccs:\n",
    "        mfccs_normalized.append((mfcc - mfccs_mean) / mfccs_std)\n",
    "    \n",
    "    return mfccs_normalized, mfccs_mean, mfccs_std\n",
    "\n",
    "\n",
    "def sample_train_data(dataset_A, dataset_B, n_frames = 128):\n",
    "\n",
    "    num_samples = min(len(dataset_A), len(dataset_B))\n",
    "    train_data_A_idx = np.arange(len(dataset_A))\n",
    "    train_data_B_idx = np.arange(len(dataset_B))\n",
    "    np.random.shuffle(train_data_A_idx)\n",
    "    np.random.shuffle(train_data_B_idx)\n",
    "    train_data_A_idx_subset = train_data_A_idx[:num_samples]\n",
    "    train_data_B_idx_subset = train_data_B_idx[:num_samples]\n",
    "\n",
    "    train_data_A = list()\n",
    "    train_data_B = list()\n",
    "\n",
    "    for idx_A, idx_B in zip(train_data_A_idx_subset, train_data_B_idx_subset):\n",
    "        data_A = dataset_A[idx_A]\n",
    "        frames_A_total = data_A.shape[1]\n",
    "        assert frames_A_total >= n_frames\n",
    "        start_A = np.random.randint(frames_A_total - n_frames + 1)\n",
    "        end_A = start_A + n_frames\n",
    "        train_data_A.append(data_A[:,start_A:end_A])\n",
    "\n",
    "        data_B = dataset_B[idx_B]\n",
    "        frames_B_total = data_B.shape[1]\n",
    "        assert frames_B_total >= n_frames\n",
    "        start_B = np.random.randint(frames_B_total - n_frames + 1)\n",
    "        end_B = start_B + n_frames\n",
    "        train_data_B.append(data_B[:,start_B:end_B])\n",
    "\n",
    "    train_data_A = np.array(train_data_A)\n",
    "    train_data_B = np.array(train_data_B)\n",
    "\n",
    "    return train_data_A, train_data_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "def train():\n",
    "    \n",
    "    num_epochs = 4000 # 5000\n",
    "    mini_batch_size = 1 # mini_batch_size = 1 is better\n",
    "    generator_learning_rate = 0.0002\n",
    "    generator_learning_rate_decay = generator_learning_rate / 200000\n",
    "    discriminator_learning_rate = 0.0001\n",
    "    discriminator_learning_rate_decay = discriminator_learning_rate / 200000\n",
    "    sampling_rate = 16000\n",
    "    num_mcep = 64\n",
    "    frame_period = 5.0\n",
    "    n_frames = 128\n",
    "    lambda_cycle = 10\n",
    "    lambda_identity = 5\n",
    "    \n",
    "    lossG = []\n",
    "    lossD = []\n",
    "    loss_num = 0\n",
    "\n",
    "    print('Preprocessing Data...')\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    wavs_A = load_wavs(wav_dir = train_A_dir, sr = sampling_rate)\n",
    "    wavs_B = load_wavs(wav_dir = train_B_dir, sr = sampling_rate)\n",
    "\n",
    "    f0s_A, timeaxes_A, sps_A, aps_A, coded_sps_A = world_encode_data(wavs = wavs_A, fs = sampling_rate, frame_period = frame_period, coded_dim = num_mcep)\n",
    "    f0s_B, timeaxes_B, sps_B, aps_B, coded_sps_B = world_encode_data(wavs = wavs_B, fs = sampling_rate, frame_period = frame_period, coded_dim = num_mcep)\n",
    "\n",
    "    log_f0s_mean_A, log_f0s_std_A = logf0_statistics(f0s_A)\n",
    "    log_f0s_mean_B, log_f0s_std_B = logf0_statistics(f0s_B)\n",
    "\n",
    "    print('Log Pitch A')\n",
    "    print('Mean: %f, Std: %f' %(log_f0s_mean_A, log_f0s_std_A))\n",
    "    print('Log Pitch B')\n",
    "    print('Mean: %f, Std: %f' %(log_f0s_mean_B, log_f0s_std_B))\n",
    "\n",
    "    coded_sps_A_transposed = transpose_in_list(lst = coded_sps_A)\n",
    "    coded_sps_B_transposed = transpose_in_list(lst = coded_sps_B)\n",
    "\n",
    "    coded_sps_A_norm, coded_sps_A_mean, coded_sps_A_std = coded_sps_normalization_fit_transoform(coded_sps = coded_sps_A_transposed)\n",
    "    print(\"Input data fixed.\")\n",
    "    coded_sps_B_norm, coded_sps_B_mean, coded_sps_B_std = coded_sps_normalization_fit_transoform(coded_sps = coded_sps_B_transposed)\n",
    "\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    np.savez(os.path.join(model_dir, 'logf0s_normalization.npz'), mean_A = log_f0s_mean_A, std_A = log_f0s_std_A, mean_B = log_f0s_mean_B, std_B = log_f0s_std_B)\n",
    "    np.savez(os.path.join(model_dir, 'mcep_normalization.npz'), mean_A = coded_sps_A_mean, std_A = coded_sps_A_std, mean_B = coded_sps_B_mean, std_B = coded_sps_B_std)\n",
    "    \n",
    "    \n",
    "    if validation_A_dir is not None:\n",
    "        validation_A_output_dir = os.path.join(output_dir, 'converted_A')\n",
    "        if not os.path.exists(validation_A_output_dir):\n",
    "            os.makedirs(validation_A_output_dir)\n",
    "\n",
    "    if validation_B_dir is not None:\n",
    "        validation_B_output_dir = os.path.join(output_dir, 'converted_B')\n",
    "        if not os.path.exists(validation_B_output_dir):\n",
    "            os.makedirs(validation_B_output_dir)\n",
    "\n",
    "    end_time = time.time()\n",
    "    time_elapsed = end_time - start_time\n",
    "\n",
    "    print('Preprocessing Done.')\n",
    "\n",
    "    print('Time Elapsed for Data Preprocessing: %02d:%02d:%02d' % (time_elapsed // 3600, (time_elapsed % 3600 // 60), (time_elapsed % 60 // 1)))\n",
    "\n",
    "    model = CycleGAN(num_features = num_mcep)\n",
    "    \n",
    "    print(\"Training start.\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        epoch += 1\n",
    "        \n",
    "        print('Epoch: %d' % epoch)\n",
    "            \n",
    "        start = time.time()\n",
    "        '''\n",
    "        if epoch > 60:\n",
    "            lambda_identity = 0\n",
    "        if epoch > 1250:\n",
    "            generator_learning_rate = max(0, generator_learning_rate - 0.0000002)\n",
    "            discriminator_learning_rate = max(0, discriminator_learning_rate - 0.0000001)\n",
    "        '''\n",
    "\n",
    "        # start_time_epoch = time.time()\n",
    "\n",
    "        dataset_A, dataset_B = sample_train_data(dataset_A = coded_sps_A_norm, dataset_B = coded_sps_B_norm, n_frames = n_frames)\n",
    "\n",
    "        n_samples = dataset_A.shape[0]\n",
    "\n",
    "        for i in range(n_samples // mini_batch_size):\n",
    "\n",
    "            num_iterations = n_samples // mini_batch_size * epoch + i\n",
    "\n",
    "            if num_iterations > 10000:\n",
    "                lambda_identity = 0\n",
    "            if num_iterations > 200000:\n",
    "                generator_learning_rate = max(0, generator_learning_rate - generator_learning_rate_decay)\n",
    "                discriminator_learning_rate = max(0, discriminator_learning_rate - discriminator_learning_rate_decay)\n",
    "\n",
    "            start = i * mini_batch_size\n",
    "            end = (i + 1) * mini_batch_size\n",
    "\n",
    "            generator_loss, discriminator_loss = model.train(input_A = dataset_A[start:end], input_B = dataset_B[start:end], lambda_cycle = lambda_cycle, lambda_identity = lambda_identity, generator_learning_rate = generator_learning_rate, discriminator_learning_rate = discriminator_learning_rate)\n",
    "\n",
    "            if i % 50 == 0:\n",
    "                # print('Iteration: {:07d}, Generator Learning Rate: {:.7f}, Discriminator Learning Rate: {:.7f}, Generator Loss : {:.3f}, Discriminator Loss : {:.3f}'.format(num_iterations, generator_learning_rate, discriminator_learning_rate, generator_loss, discriminator_loss))\n",
    "                pass\n",
    "            \n",
    "            if i % 50 == 0:\n",
    "                lossG.append(generator_loss)\n",
    "                lossD.append(discriminator_loss)\n",
    "                loss_num += 1\n",
    "                \n",
    "        # end_time_epoch = time.time()\n",
    "        # time_elapsed_epoch = end_time_epoch - start_time_epoch\n",
    "\n",
    "        # print('Time Elapsed for This Epoch: %02d:%02d:%02d' % (time_elapsed_epoch // 3600, (time_elapsed_epoch % 3600 // 60), (time_elapsed_epoch % 60 // 1)))\n",
    "\n",
    "        if validation_A_dir is not None:\n",
    "            if epoch % 50 == 0:\n",
    "                print('Generating Validation Data B from A...')\n",
    "                for file in os.listdir(validation_A_dir):\n",
    "                    filepath = os.path.join(validation_A_dir, file)\n",
    "                    wav, _ = librosa.load(filepath, sr = sampling_rate, mono = True)\n",
    "                    wav = wav_padding(wav = wav, sr = sampling_rate, frame_period = frame_period, multiple = 4)\n",
    "                    f0, timeaxis, sp, ap = world_decompose(wav = wav, fs = sampling_rate, frame_period = frame_period)\n",
    "                    f0_converted = pitch_conversion(f0 = f0, mean_log_src = log_f0s_mean_A, std_log_src = log_f0s_std_A, mean_log_target = log_f0s_mean_B, std_log_target = log_f0s_std_B)\n",
    "                    coded_sp = world_encode_spectral_envelop(sp = sp, fs = sampling_rate, dim = num_mcep)\n",
    "                    coded_sp_transposed = coded_sp.T\n",
    "                    coded_sp_norm = (coded_sp_transposed - coded_sps_A_mean) / coded_sps_A_std\n",
    "                    coded_sp_converted_norm = model.test(inputs = np.array([coded_sp_norm]), direction = 'A2B')[0]\n",
    "                    coded_sp_converted = coded_sp_converted_norm * coded_sps_B_std + coded_sps_B_mean\n",
    "                    coded_sp_converted = coded_sp_converted.T\n",
    "                    coded_sp_converted = np.ascontiguousarray(coded_sp_converted)\n",
    "                    decoded_sp_converted = world_decode_spectral_envelop(coded_sp = coded_sp_converted, fs = sampling_rate)\n",
    "                    wav_transformed = world_speech_synthesis(f0 = f0_converted, decoded_sp = decoded_sp_converted, ap = ap, fs = sampling_rate, frame_period = frame_period)\n",
    "                    librosa.output.write_wav(os.path.join(validation_A_output_dir, os.path.basename(file)), wav_transformed, sampling_rate)\n",
    "\n",
    "        if validation_B_dir is not None:\n",
    "            if epoch % 50 == 0:\n",
    "                print('Generating Validation Data A from B...')\n",
    "                for file in os.listdir(validation_B_dir):\n",
    "                    filepath = os.path.join(validation_B_dir, file)\n",
    "                    wav, _ = librosa.load(filepath, sr = sampling_rate, mono = True)\n",
    "                    wav = wav_padding(wav = wav, sr = sampling_rate, frame_period = frame_period, multiple = 4)\n",
    "                    f0, timeaxis, sp, ap = world_decompose(wav = wav, fs = sampling_rate, frame_period = frame_period)\n",
    "                    f0_converted = pitch_conversion(f0 = f0, mean_log_src = log_f0s_mean_B, std_log_src = log_f0s_std_B, mean_log_target = log_f0s_mean_A, std_log_target = log_f0s_std_A)\n",
    "                    coded_sp = world_encode_spectral_envelop(sp = sp, fs = sampling_rate, dim = num_mcep)\n",
    "                    coded_sp_transposed = coded_sp.T\n",
    "                    coded_sp_norm = (coded_sp_transposed - coded_sps_B_mean) / coded_sps_B_std\n",
    "                    coded_sp_converted_norm = model.test(inputs = np.array([coded_sp_norm]), direction = 'B2A')[0]\n",
    "                    coded_sp_converted = coded_sp_converted_norm * coded_sps_A_std + coded_sps_A_mean\n",
    "                    coded_sp_converted = coded_sp_converted.T\n",
    "                    coded_sp_converted = np.ascontiguousarray(coded_sp_converted)\n",
    "                    decoded_sp_converted = world_decode_spectral_envelop(coded_sp = coded_sp_converted, fs = sampling_rate)\n",
    "                    wav_transformed = world_speech_synthesis(f0 = f0_converted, decoded_sp = decoded_sp_converted, ap = ap, fs = sampling_rate, frame_period = frame_period)\n",
    "                    librosa.output.write_wav(os.path.join(validation_B_output_dir, os.path.basename(file)), wav_transformed, sampling_rate)\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            model.save(directory = model_dir, filename = model_name)\n",
    "            \n",
    "        if epoch % 10 == 0:\n",
    "            if not os.path.exists(figure_dir):\n",
    "                os.makedirs(figure_dir)\n",
    "            x = np.linspace(0, loss_num, loss_num)\n",
    "            plt.plot(x, lossG, label=\"Gen\")\n",
    "            plt.plot(x, lossD, label=\"Dis\")\n",
    "            plt.savefig(figure_dir + \"/\" + \"epoch_{:05}\".format(epoch) + \".png\")\n",
    "            \n",
    "    elapsed_time = time.time() - start\n",
    "    print (\"elapsed time for one epoch:{0:.4f}\".format(elapsed_time) + \"[sec]\")\n",
    "\n",
    "    model.save(directory = model_dir, filename = model_name)\n",
    "            \n",
    "    x = np.linspace(0, loss_num, loss_num)\n",
    "    plt.plot(x, lossG, label=\"Gen\")\n",
    "    plt.plot(x, lossD, label=\"Dis\")\n",
    "    plt.savefig(\"figures/\" + model_name + \"/\" + \"{:05}\".format(epoch) + \"_epoch.png\")\n",
    "            \n",
    "    end_time = time.time()\n",
    "    time_elapsed = end_time - start_time\n",
    "    print('Time Elapsed for Training: %02d:%02d:%02d' % (time_elapsed // 3600, (time_elapsed % 3600 // 60), (time_elapsed % 60 // 1)))\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \n",
    "    isContinue = False\n",
    "    \n",
    "    num_pre_epochs = 0\n",
    "    num_epochs = 4000\n",
    "    mini_batch_size = 1\n",
    "    generator_learning_rate = 0.0002\n",
    "    generator_learning_rate_decay = generator_learning_rate / 200000\n",
    "    discriminator_learning_rate = 0.0001\n",
    "    discriminator_learning_rate_decay = discriminator_learning_rate / 200000\n",
    "    sampling_rate = 16000\n",
    "    num_mcep = 64\n",
    "    frame_period = 5.0\n",
    "    n_frames = 64\n",
    "    lambda_cycle = 10\n",
    "    lambda_identity = 5\n",
    "    \n",
    "    lossG = []\n",
    "    lossD = []\n",
    "    loss_num = 0\n",
    "    \n",
    "    print('Preprocessing Data...')\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    wavs_A = load_wavs(wav_dir = train_A_dir, sr = sampling_rate)\n",
    "    wavs_B = load_wavs(wav_dir = train_B_dir, sr = sampling_rate)\n",
    "\n",
    "    f0s_A, timeaxes_A, sps_A, aps_A, coded_sps_A = world_encode_data(wavs = wavs_A, fs = sampling_rate, frame_period = frame_period, coded_dim = num_mcep)\n",
    "    f0s_B, timeaxes_B, sps_B, aps_B, coded_sps_B = world_encode_data(wavs = wavs_B, fs = sampling_rate, frame_period = frame_period, coded_dim = num_mcep)\n",
    "\n",
    "    log_f0s_mean_A, log_f0s_std_A = logf0_statistics(f0s_A)\n",
    "    log_f0s_mean_B, log_f0s_std_B = logf0_statistics(f0s_B)\n",
    "\n",
    "    print('Log Pitch A')\n",
    "    print('Mean: %f, Std: %f' %(log_f0s_mean_A, log_f0s_std_A))\n",
    "    print('Log Pitch B')\n",
    "    print('Mean: %f, Std: %f' %(log_f0s_mean_B, log_f0s_std_B))\n",
    "\n",
    "    coded_sps_A_transposed = transpose_in_list(lst = coded_sps_A)\n",
    "    coded_sps_B_transposed = transpose_in_list(lst = coded_sps_B)\n",
    "\n",
    "    coded_sps_A_norm, coded_sps_A_mean, coded_sps_A_std = coded_sps_normalization_fit_transoform(coded_sps = coded_sps_A_transposed)\n",
    "    print(\"Input data fixed.\")\n",
    "    coded_sps_B_norm, coded_sps_B_mean, coded_sps_B_std = coded_sps_normalization_fit_transoform(coded_sps = coded_sps_B_transposed)\n",
    "\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    np.savez(os.path.join(model_dir, 'logf0s_normalization.npz'), mean_A = log_f0s_mean_A, std_A = log_f0s_std_A, mean_B = log_f0s_mean_B, std_B = log_f0s_std_B)\n",
    "    np.savez(os.path.join(model_dir, 'mcep_normalization.npz'), mean_A = coded_sps_A_mean, std_A = coded_sps_A_std, mean_B = coded_sps_B_mean, std_B = coded_sps_B_std)    \n",
    "    \n",
    "    if validation_A_dir is not None:\n",
    "        validation_A_output_dir = os.path.join(output_dir, 'converted_A')\n",
    "        if not os.path.exists(validation_A_output_dir):\n",
    "            os.makedirs(validation_A_output_dir)\n",
    "\n",
    "    if validation_B_dir is not None:\n",
    "        validation_B_output_dir = os.path.join(output_dir, 'converted_B')\n",
    "        if not os.path.exists(validation_B_output_dir):\n",
    "            os.makedirs(validation_B_output_dir)\n",
    "\n",
    "    end_time = time.time()\n",
    "    time_elapsed = end_time - start_time\n",
    "\n",
    "    print('Preprocessing Done.')\n",
    "    \n",
    "    print('Time Elapsed for Data Preprocessing: %02d:%02d:%02d' % (time_elapsed // 3600, (time_elapsed % 3600 // 60), (time_elapsed % 60 // 1)))\n",
    "\n",
    "    model = CycleGAN(num_features = num_mcep)\n",
    "    if (isContinue):\n",
    "        model.load(filepath = os.path.join(model_dir, model_name))\n",
    "    \n",
    "    print(\"Training start.\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch += num_pre_epochs\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        print('Epoch: %d' % epoch)\n",
    "\n",
    "        dataset_A, dataset_B = sample_train_data(dataset_A = coded_sps_A_norm, dataset_B = coded_sps_B_norm, n_frames = n_frames)\n",
    "\n",
    "        n_samples = dataset_A.shape[0]\n",
    "\n",
    "        for i in range(n_samples // mini_batch_size):\n",
    "\n",
    "            num_iterations = n_samples // mini_batch_size * epoch + i\n",
    "\n",
    "            if num_iterations > 10000:\n",
    "                lambda_identity = 0\n",
    "            if num_iterations > 200000:\n",
    "                generator_learning_rate = max(0, generator_learning_rate - generator_learning_rate_decay)\n",
    "                discriminator_learning_rate = max(0, discriminator_learning_rate - discriminator_learning_rate_decay)\n",
    "\n",
    "            start = i * mini_batch_size\n",
    "            end = (i + 1) * mini_batch_size\n",
    "\n",
    "            generator_loss, discriminator_loss = model.train(input_A = dataset_A[start:end], input_B = dataset_B[start:end], lambda_cycle = lambda_cycle, lambda_identity = lambda_identity, generator_learning_rate = generator_learning_rate, discriminator_learning_rate = discriminator_learning_rate)\n",
    "            \n",
    "            if i % 50 == 0:\n",
    "                lossG.append(generator_loss)\n",
    "                lossD.append(discriminator_loss)\n",
    "                loss_num += 1\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            model.save(directory = model_dir, filename = model_name)\n",
    "            \n",
    "        if epoch % 10 == 0:\n",
    "            if not os.path.exists(figure_dir):\n",
    "                os.makedirs(figure_dir)\n",
    "            x = np.linspace(0, loss_num, loss_num)\n",
    "            plt.plot(x, lossG, label=\"Gen\")\n",
    "            plt.plot(x, lossD, label=\"Dis\")\n",
    "            plt.legend()\n",
    "            plt.savefig(figure_dir + \"/\" + \"epoch_{:05}\".format(epoch) + \".png\")\n",
    "            \n",
    "        elapsed_time = time.time() - start\n",
    "        print('Time Elapsed for one epoch: %02d:%02d:%02d' % (elapsed_time // 3600, (elapsed_time % 3600 // 60), (elapsed_time % 60 // 1)))        \n",
    "            \n",
    "    model.save(directory = model_dir, filename = model_name)\n",
    "            \n",
    "    x = np.linspace(0, loss_num, loss_num)\n",
    "    plt.plot(x, lossG, label=\"Gen\")\n",
    "    plt.plot(x, lossD, label=\"Dis\")\n",
    "    plt.legend()\n",
    "    plt.savefig(figure_dir + \"/\" + \"epoch_{:05}\".format(epoch) + \".png\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
